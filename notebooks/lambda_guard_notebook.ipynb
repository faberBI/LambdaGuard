{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqqg7g2-tzAv"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üõ°Ô∏è Œª-Guard Multi-Model Experiment - Python Notebook\n",
        "# ============================================================\n",
        "\n",
        "# This notebook demonstrates the usage of the Œª-Guard package\n",
        "# for detecting structural overfitting in Gradient Boosting\n",
        "# and other tree-based models. It leverages your `opi.py`\n",
        "# and `cusum.py` modules for computing overfitting indices\n",
        "# (OFI) and detecting the change point where the model\n",
        "# starts memorizing structure rather than learning signal.\n",
        "# ============================================================\n",
        "\n",
        "# -----------------------------\n",
        "# Imports\n",
        "# -----------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "import seaborn as sns\n",
        "\n",
        "# Import functions from your lambdaguard package\n",
        "from lambdaguard.ofi import (\n",
        "    generalization_index,     # Computes alignment (A), complexity (C) and generalization index (GI)\n",
        "    instability_index,        # Measures sensitivity of predictions to small input perturbations\n",
        "    create_model,             # Factory function to create GBR, XGB, LGBM, or CAT models\n",
        "    run_experiment_multi_model,# Runs full experiment across multiple hyperparameter combinations\n",
        "    regression_test           # Optional: performs regression analysis (Gap vs OFI)\n",
        ")\n",
        "from lambdaguard.cusum import lambda_detect  # Detects structural overfitting change points using OFI\n",
        "\n",
        "# -----------------------------\n",
        "# Generate Synthetic Dataset\n",
        "# -----------------------------\n",
        "# We create a synthetic regression dataset to demonstrate multi-model overfitting detection.\n",
        "X, y = make_regression(\n",
        "    n_samples=1000,      # Number of samples\n",
        "    n_features=10,       # Number of features\n",
        "    n_informative=8,     # Features carrying signal\n",
        "    noise=10.0,          # Noise level\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Run Multi-Model Experiment\n",
        "# -----------------------------\n",
        "# This function evaluates multiple tree-based models (GBR, LGBM, CAT)\n",
        "# across different hyperparameters. It computes:\n",
        "# - A: alignment (signal captured by model)\n",
        "# - C: structural complexity (how fragmented the feature space is)\n",
        "# - S: instability (sensitivity to input perturbations)\n",
        "# - OFI: Overfitting Index = (C / (A + C)) * S\n",
        "df_multi = run_experiment_multi_model(\n",
        "    X, y,\n",
        "    dataset_name=\"Synthetic Database\",\n",
        "    model_names=[\"GBR\",\"LGBM\",\"CAT\"]\n",
        ")\n",
        "\n",
        "print(\"Experiment dataframe preview:\")\n",
        "display(df_multi.head())\n",
        "\n",
        "# -----------------------------\n",
        "# Detect Structural Overfitting\n",
        "# -----------------------------\n",
        "# For each model type, we use Œª-Guard's `lambda_detect` function\n",
        "# to identify the point where the model starts to overfit structurally.\n",
        "# This uses the normalized OFI and cumulative sum (CUSUM) method.\n",
        "\n",
        "list_model = df_multi['model'].unique()\n",
        "for model_name in list_model:\n",
        "    # Optional regression analysis for diagnostics\n",
        "    regression_test(df_multi[df_multi['model'] == model_name])\n",
        "\n",
        "    # Detect structural overfitting\n",
        "    result = lambda_detect(df_multi, model_name=model_name)"
      ]
    }
  ]
}
